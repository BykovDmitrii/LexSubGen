import re
from typing import List, Tuple, Dict, Union

import numpy as np

GapScore = Union[float, Tuple[float, List[str]]]
WORD_PAT_RE = re.compile(r"^[A-Za-z]+$")


def gap_score(
    gold_substitutes: List[str],
    gold_weights: List[int],
    model_prediction: np.ndarray,
    word2id: Dict[str, int],
    candidates: List[str],
    return_ranked_candidates: bool = False,
) -> Tuple[GapScore, GapScore, GapScore]:
    """
    Function for calculating GAP metric.
    Example:
        gold_substitutes = ["intelligent", "clever"]
        gold_weights = [3, 2]
        candidates = ["positive", "intelligent", "smart", "clever", "talented"]

        word2id = {
            "happy": 0, "bright": 1, "positive": 2, "intelligent": 3,
            "clever": 4, "smart": 5, "talented": 6, "curious": 7,
            ....
            "watch": 31998, "dogs": 31999
        }
        model_prediction = [
            0.0581, 0.0872 , 0.1918, 0.1162,
            0.1453, 0.1744, 0.0988, 0.1279
            ...
            0.0013, 0.006
        ]

        We can compute sort model_prediction in descending order:
            ["positive", "smart", "clever", "curious", "intelligent", "talented", "bright", ....]
        Ranks of gold substitutes in all vocabulary:
            {"clever": 3, "intelligent": 5"}
        Ranks of gold substitutes in candidates:
            {"clever": 3, "intelligent": 4"}
        Perfectly ranking must be:
            ["intelligent", "clever", ....]
        Denominator of GAP:
            (3 / 1) + ((3 + 2) / 2) = 5.5
        Nominator of GAP:
            (2 / 3) + ((2 + 3) / 4) = 1.9166
        Nominator of GAP_all_vocab:
            (2 / 3) + ((2 + 3) / 5) = 1.6666
        GAP = 0.3484
        For more formal description look Section 4.2 in https://www.aclweb.org/anthology/P10-1097.pdf.

    Args:
        gold_substitutes: substitutes generated by annotators
        gold_weights: corresponding number of annotators for each substitute
        model_prediction: probability distribution (scores) from model over the vocabulary
        word2id: python dictionary that maps words from vocabulary to their indices in the vocabulary
        candidates: list of candidate words from dataset
        return_ranked_candidates: boolean flag, if True return both metrics and list of ranked candidates
    Returns:
        function returns 3 metrics (3 float values):
            GAP - base metric for candidate-ranking task.
            GAP_normalized - similar to GAP metric, but we exclude MWE (multi word expressions) from gold_substitutes
            GAP_vocab_normalized - similar to GAP metric, but we exclude all OOV words from gold_substitutes
    """
    gap, gap_normalized, gap_vocab_normalized = None, None, None

    gold_map = {word: weight for word, weight in zip(gold_substitutes, gold_weights)}
    # GAP with MWEs
    if gold_map:
        gap = compute_gap(
            gold_map, candidates, model_prediction, word2id, return_ranked_candidates
        )

    # GAP without MWEs
    gold_map_normalized = {
        word: weight
        for word, weight in zip(gold_substitutes, gold_weights)
        if WORD_PAT_RE.match(word)
    }
    if gold_map_normalized:
        normalized_candidates = [w for w in candidates if WORD_PAT_RE.match(w)]
        gap_normalized = compute_gap(
            gold_map_normalized,
            normalized_candidates,
            model_prediction,
            word2id,
            return_ranked_candidates,
        )

    # GAP without OOV words
    gold_map_vocab_normalized = {
        word: weight
        for word, weight in zip(gold_substitutes, gold_weights)
        if word in word2id.keys()
    }
    if gold_map_vocab_normalized:
        vocab_normalized_candidates = [w for w in candidates if w in word2id.keys()]
        gap_vocab_normalized = compute_gap(
            gold_map_vocab_normalized,
            vocab_normalized_candidates,
            model_prediction,
            word2id,
            return_ranked_candidates,
        )
    return gap, gap_normalized, gap_vocab_normalized


def compute_gap_nominator(
    model_prediction: np.ndarray,
    words: List[str],
    word2id: Dict[str, int],
    gold2weight: Dict[str, int],
    return_ranked_words: bool = False,
) -> GapScore:
    """
    Method for computing nominator for GAP score.

    Args:
        model_prediction: NumPy array with probabilities of generated substitutes.
        words: List of words among which Substitute Generator ranks gold words.
        word2id: Dictionary that maps word from Substitute Generator vocabulary to its index.
        gold2weight: Dictionary that maps gold word to its annotators number.
        return_ranked_words: Bool flag, if True then return a list of ranked words.
    Returns:
        nominator: computed nominator for GAP score.
        ranked_words: Additionally return a list of ranked words, if 'return_ranked_words' equal True.
    """
    cumsum = 0
    nominator = 0.0

    words_in_vocab = [w for w in words if w in word2id]
    word_scores = np.array([model_prediction[word2id[word]] for word in words_in_vocab])
    word2rank = {
        word: (word_scores > score).sum() + 1
        for word, score in zip(words_in_vocab, word_scores)
    }
    word2rank = sorted(word2rank.items(), key=lambda x: x[1])
    word2rank = [(word, idx + 1) for idx, (word, _) in enumerate(word2rank)]

    for word, rank in word2rank:
        weight = gold2weight.get(word, 0)
        if weight:
            cumsum += weight
            nominator += cumsum / rank
    if return_ranked_words:
        ranked_words = [word for word, rank in word2rank]
        for word in words:
            if word not in word2id:
                ranked_words.append(word)
        return nominator, ranked_words
    return nominator


def compute_gap(
    gold_mapping: Dict[str, int],
    candidates: List[str],
    model_prediction: np.ndarray,
    word2id: Dict[str, int],
    return_ranked_candidates: bool = False,
) -> GapScore:
    """
    Method for computing GAP metric.

    Args:
        gold_mapping: Dictionary that maps gold word to its annotators number.
        candidates: List of candidate words.
        model_prediction: NumPy array with probabilities of generated substitutes.
        word2id: Dictionary that maps word from Substitute Generator vocabulary to its index.
        return_ranked_candidates: Bool flag, if True then return a list of ranked candidates.
    Returns:
        gap: computed GAP score.
        ranked_candidates: Additionally return a list of ranked candidates, if 'return_ranked_candidates' equal True.
    """
    gap_denominator = (
        np.cumsum(list(gold_mapping.values())) / np.arange(1, len(gold_mapping) + 1)
    ).sum()
    ranked_candidates = None
    gap_nominator = compute_gap_nominator(
        model_prediction, candidates, word2id, gold_mapping, return_ranked_candidates
    )
    if return_ranked_candidates:
        gap_nominator, ranked_candidates = gap_nominator
    gap = gap_nominator / gap_denominator

    if return_ranked_candidates:
        return gap, ranked_candidates
    return gap
